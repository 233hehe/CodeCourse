{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb7596d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Linear Algebra\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87556c1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:07.966517Z",
     "iopub.status.busy": "2023-02-10T04:43:07.966050Z",
     "iopub.status.idle": "2023-02-10T04:43:09.389061Z",
     "shell.execute_reply": "2023-02-10T04:43:09.384712Z"
    },
    "origin_pos": 3,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724b7b22",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Scalars are implemented as tensors \n",
    "that contain only one element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ce7076a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.405351Z",
     "iopub.status.busy": "2023-02-10T04:43:09.400475Z",
     "iopub.status.idle": "2023-02-10T04:43:09.431198Z",
     "shell.execute_reply": "2023-02-10T04:43:09.422088Z"
    },
    "origin_pos": 8,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(3.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "x + y, x * y, x / y, x**y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6bce6b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can think of vectors\n",
    "as fixed-length arrays of scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc54895d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.435603Z",
     "iopub.status.busy": "2023-02-10T04:43:09.435008Z",
     "iopub.status.idle": "2023-02-10T04:43:09.448281Z",
     "shell.execute_reply": "2023-02-10T04:43:09.446032Z"
    },
    "origin_pos": 13,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba090652",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We access a tensor's elements via indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d22d360",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.452637Z",
     "iopub.status.busy": "2023-02-10T04:43:09.451851Z",
     "iopub.status.idle": "2023-02-10T04:43:09.466778Z",
     "shell.execute_reply": "2023-02-10T04:43:09.465749Z"
    },
    "origin_pos": 17,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eaba1f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In code, this corresponds to the tensor's length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7b4714b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.474115Z",
     "iopub.status.busy": "2023-02-10T04:43:09.473538Z",
     "iopub.status.idle": "2023-02-10T04:43:09.484660Z",
     "shell.execute_reply": "2023-02-10T04:43:09.483722Z"
    },
    "origin_pos": 19,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print(len(x))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1853eed0",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Tensors with just one axis have shapes with just one element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e11fdc38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.497341Z",
     "iopub.status.busy": "2023-02-10T04:43:09.494600Z",
     "iopub.status.idle": "2023-02-10T04:43:09.513348Z",
     "shell.execute_reply": "2023-02-10T04:43:09.509894Z"
    },
    "origin_pos": 21,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562d5c55",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can convert any appropriately sized $m \\times n$ tensor \n",
    "into an $m \\times n$ matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1ea4952",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.522539Z",
     "iopub.status.busy": "2023-02-10T04:43:09.519139Z",
     "iopub.status.idle": "2023-02-10T04:43:09.541163Z",
     "shell.execute_reply": "2023-02-10T04:43:09.532731Z"
    },
    "origin_pos": 24,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6).reshape(3, 2)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b321c1",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Matrix's transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccfcdfd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.548191Z",
     "iopub.status.busy": "2023-02-10T04:43:09.547827Z",
     "iopub.status.idle": "2023-02-10T04:43:09.571288Z",
     "shell.execute_reply": "2023-02-10T04:43:09.570452Z"
    },
    "origin_pos": 28,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 4],\n",
       "        [1, 3, 5]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04148b3d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Symmetric matrices are the subset of square matrices\n",
    "that are equal to their own transposes:\n",
    "$\\mathbf{A} = \\mathbf{A}^\\top$\n",
    "  \n",
    " 对称矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e992c013",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.575384Z",
     "iopub.status.busy": "2023-02-10T04:43:09.574557Z",
     "iopub.status.idle": "2023-02-10T04:43:09.583352Z",
     "shell.execute_reply": "2023-02-10T04:43:09.582564Z"
    },
    "origin_pos": 32,
    "scrolled": true,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\n",
    "A == A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5079ea65",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Tensors\n",
    "give us a generic way to describe \n",
    "extensions to $n^{\\mathrm{th}}$-order arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9b5c3cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.587081Z",
     "iopub.status.busy": "2023-02-10T04:43:09.586509Z",
     "iopub.status.idle": "2023-02-10T04:43:09.607574Z",
     "shell.execute_reply": "2023-02-10T04:43:09.596531Z"
    },
    "origin_pos": 37,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(24).reshape(2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30ac56f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.612428Z",
     "iopub.status.busy": "2023-02-10T04:43:09.611839Z",
     "iopub.status.idle": "2023-02-10T04:43:09.633303Z",
     "shell.execute_reply": "2023-02-10T04:43:09.632476Z"
    },
    "origin_pos": 42,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor([[ 0.,  2.,  4.],\n",
       "         [ 6.,  8., 10.]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
    "B = A.clone()\n",
    "A, A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283beee9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Elementwise product of two matrices\n",
    "is called their *Hadamard product*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11e761f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.638728Z",
     "iopub.status.busy": "2023-02-10T04:43:09.636388Z",
     "iopub.status.idle": "2023-02-10T04:43:09.648829Z",
     "shell.execute_reply": "2023-02-10T04:43:09.647990Z"
    },
    "origin_pos": 46,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  4.],\n",
       "        [ 9., 16., 25.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5209789e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Adding or multiplying a scalar and a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2da5233",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.655429Z",
     "iopub.status.busy": "2023-02-10T04:43:09.654794Z",
     "iopub.status.idle": "2023-02-10T04:43:09.672534Z",
     "shell.execute_reply": "2023-02-10T04:43:09.662047Z"
    },
    "origin_pos": 49,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2,  3,  4,  5],\n",
       "          [ 6,  7,  8,  9],\n",
       "          [10, 11, 12, 13]],\n",
       " \n",
       "         [[14, 15, 16, 17],\n",
       "          [18, 19, 20, 21],\n",
       "          [22, 23, 24, 25]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "X = torch.arange(24).reshape(2, 3, 4)\n",
    "a + X, (a * X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2291446b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The sum of a tensor's elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f25c98b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.678661Z",
     "iopub.status.busy": "2023-02-10T04:43:09.676173Z",
     "iopub.status.idle": "2023-02-10T04:43:09.700888Z",
     "shell.execute_reply": "2023-02-10T04:43:09.694750Z"
    },
    "origin_pos": 54,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2.]), tensor(3.))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(3, dtype=torch.float32)\n",
    "x, x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a5d6e8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sums over the elements of tensors of arbitrary shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a63ac705",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.714111Z",
     "iopub.status.busy": "2023-02-10T04:43:09.706728Z",
     "iopub.status.idle": "2023-02-10T04:43:09.736834Z",
     "shell.execute_reply": "2023-02-10T04:43:09.730540Z"
    },
    "origin_pos": 58,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), tensor(15.))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, A.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735326ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Specify the axes \n",
    "along which the tensor should be reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5105ae5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.745095Z",
     "iopub.status.busy": "2023-02-10T04:43:09.741822Z",
     "iopub.status.idle": "2023-02-10T04:43:09.759514Z",
     "shell.execute_reply": "2023-02-10T04:43:09.756458Z"
    },
    "origin_pos": 61,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([3]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, A.sum(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abb04820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.763210Z",
     "iopub.status.busy": "2023-02-10T04:43:09.762890Z",
     "iopub.status.idle": "2023-02-10T04:43:09.779757Z",
     "shell.execute_reply": "2023-02-10T04:43:09.774594Z"
    },
    "origin_pos": 64,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, A.sum(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8820f115",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.800109Z",
     "iopub.status.busy": "2023-02-10T04:43:09.796287Z",
     "iopub.status.idle": "2023-02-10T04:43:09.817425Z",
     "shell.execute_reply": "2023-02-10T04:43:09.808926Z"
    },
    "origin_pos": 67,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=[0, 1]) == A.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79409a02",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A related quantity is the *mean*, also called the *average*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80a02ce8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.823797Z",
     "iopub.status.busy": "2023-02-10T04:43:09.823480Z",
     "iopub.status.idle": "2023-02-10T04:43:09.841011Z",
     "shell.execute_reply": "2023-02-10T04:43:09.835543Z"
    },
    "origin_pos": 71,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.5000), tensor(2.5000))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(), A.sum() / A.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79193e6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.846242Z",
     "iopub.status.busy": "2023-02-10T04:43:09.845923Z",
     "iopub.status.idle": "2023-02-10T04:43:09.862274Z",
     "shell.execute_reply": "2023-02-10T04:43:09.861271Z"
    },
    "origin_pos": 74,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.5000, 2.5000, 3.5000]), tensor([1.5000, 2.5000, 3.5000]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(axis=0), A.sum(axis=0) / A.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2a4acd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Keep the number of axes unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccb7262c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.867160Z",
     "iopub.status.busy": "2023-02-10T04:43:09.866576Z",
     "iopub.status.idle": "2023-02-10T04:43:09.892440Z",
     "shell.execute_reply": "2023-02-10T04:43:09.887995Z"
    },
    "origin_pos": 77,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.],\n",
       "         [12.]]),\n",
       " torch.Size([2, 1]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A = A.sum(axis=1, keepdims=True)\n",
    "sum_A, sum_A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d693cd20",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Divide `A` by `sum_A` with broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88e48f63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.897444Z",
     "iopub.status.busy": "2023-02-10T04:43:09.896620Z",
     "iopub.status.idle": "2023-02-10T04:43:09.908231Z",
     "shell.execute_reply": "2023-02-10T04:43:09.907166Z"
    },
    "origin_pos": 80,
    "scrolled": true,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.3333, 0.6667],\n",
       "        [0.2500, 0.3333, 0.4167]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A / sum_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c23b8bc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The cumulative sum of elements of `A` along some axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f942be83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.912520Z",
     "iopub.status.busy": "2023-02-10T04:43:09.912209Z",
     "iopub.status.idle": "2023-02-10T04:43:09.932069Z",
     "shell.execute_reply": "2023-02-10T04:43:09.929039Z"
    },
    "origin_pos": 82,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 5., 7.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bc2565",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The *dot product* of two vectors is a sum over the products of the elements at the same position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9284767a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.936333Z",
     "iopub.status.busy": "2023-02-10T04:43:09.935713Z",
     "iopub.status.idle": "2023-02-10T04:43:09.950173Z",
     "shell.execute_reply": "2023-02-10T04:43:09.949076Z"
    },
    "origin_pos": 86,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2.]), tensor([1., 1., 1.]), tensor(3.))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(3, dtype = torch.float32)\n",
    "x, y, torch.dot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0b26b8",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We can calculate the dot product of two vectors \n",
    "by performing an elementwise multiplication followed by a sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ee53487",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.954684Z",
     "iopub.status.busy": "2023-02-10T04:43:09.953708Z",
     "iopub.status.idle": "2023-02-10T04:43:09.963037Z",
     "shell.execute_reply": "2023-02-10T04:43:09.962079Z"
    },
    "origin_pos": 91,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fea3fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The matrix-vector product $\\mathbf{A}\\mathbf{x}$\n",
    "is simply a column vector of length $m$,\n",
    "whose $i^\\mathrm{th}$ element is the dot product \n",
    "$\\mathbf{a}^\\top_i \\mathbf{x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d28f5fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.978568Z",
     "iopub.status.busy": "2023-02-10T04:43:09.975816Z",
     "iopub.status.idle": "2023-02-10T04:43:09.993670Z",
     "shell.execute_reply": "2023-02-10T04:43:09.992841Z"
    },
    "origin_pos": 99,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([3]), tensor([ 5., 14.]), tensor([ 5., 14.]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, x.shape, torch.mv(A, x), A@x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82335f6a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can think of the matrix-matrix multiplication $\\mathbf{AB}$\n",
    "as performing $m$ matrix-vector products \n",
    "or $m \\times n$ dot products \n",
    "and stitching the results together \n",
    "to form an $n \\times m$ matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11e4a002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:09.997909Z",
     "iopub.status.busy": "2023-02-10T04:43:09.997392Z",
     "iopub.status.idle": "2023-02-10T04:43:10.015366Z",
     "shell.execute_reply": "2023-02-10T04:43:10.010781Z"
    },
    "origin_pos": 104,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.,  3.,  3.,  3.],\n",
       "         [12., 12., 12., 12.]]),\n",
       " tensor([[ 3.,  3.,  3.,  3.],\n",
       "         [12., 12., 12., 12.]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.ones(3, 4)\n",
    "torch.mm(A, B), A@B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09696f8e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The $\\ell_2$ *norm*\n",
    "$$\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1592538d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:10.020208Z",
     "iopub.status.busy": "2023-02-10T04:43:10.018213Z",
     "iopub.status.idle": "2023-02-10T04:43:10.037592Z",
     "shell.execute_reply": "2023-02-10T04:43:10.034612Z"
    },
    "origin_pos": 109,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0accfc45",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The $\\ell_1$ norm\n",
    "$$\\|\\mathbf{x}\\|_1 = \\sum_{i=1}^n \\left|x_i \\right|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3e8deaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:10.047840Z",
     "iopub.status.busy": "2023-02-10T04:43:10.044656Z",
     "iopub.status.idle": "2023-02-10T04:43:10.058843Z",
     "shell.execute_reply": "2023-02-10T04:43:10.057553Z"
    },
    "origin_pos": 114,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(u).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657f5293",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The *Frobenius norm*, \n",
    "which is much easier to compute\n",
    "$$\\|\\mathbf{X}\\|_F = \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n x_{ij}^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bceb62aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:43:10.066146Z",
     "iopub.status.busy": "2023-02-10T04:43:10.063019Z",
     "iopub.status.idle": "2023-02-10T04:43:10.079960Z",
     "shell.execute_reply": "2023-02-10T04:43:10.077528Z"
    },
    "origin_pos": 119,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.ones((4, 9)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f838e0f",
   "metadata": {},
   "source": [
    "## 练习\n",
    "给出两个矩阵A和B，证明“它们转置的和”等于“它们和的转置”，即A⊤+B⊤=(A+B)⊤。  \n",
    "给定任意方阵A，A+A⊤总是对称的吗?为什么?  \n",
    "本节中定义了形状(2,3,4)的张量X。len(X)的输出结果是什么？  \n",
    "对于任意形状的张量X,len(X)是否总是对应于X特定轴的长度?这个轴是什么?  \n",
    "运行A/A.sum(axis=1)，看看会发生什么。请分析一下原因？  \n",
    "考虑一个具有形状(2,3,4)的张量，在轴0、1、2上的求和输出是什么形状?  \n",
    "为linalg.norm函数提供3个或更多轴的张量，并观察其输出。对于任意形状的张量这个函数计算得到什么?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a64afd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3670, -1.5078, -1.2647,  0.2733],\n",
      "        [ 1.2319,  0.9475,  0.5649,  2.6652],\n",
      "        [ 0.9261, -1.2197,  0.7675, -0.8550]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1.\n",
    "A = torch.randn(3, 4)\n",
    "print(A)\n",
    "A == A.T.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2539d075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2.\n",
    "A = torch.randn(3, 4)\n",
    "B = torch.randn(3, 4)\n",
    "A.T+B.T == (A+B).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "697dd6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 3 因为 (A+A.T).T = A.T + A.T.T(第二个已经证实了)= A.T + A (第一个已经证实了) \n",
    "A = torch.randn(3, 3)\n",
    "A + A.T == (A + A.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ed77721e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "## 4 \n",
    "\n",
    "print(X.shape)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "90e35bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "100\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "## 5 总是第一个\n",
    "X = torch.randn(3,5,4)\n",
    "print(len(X))\n",
    "X = torch.randn(100,5,4)\n",
    "print(len(X))\n",
    "X = torch.randn(98,5,4)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5a574bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.2000, 0.2857],\n",
      "        [1.0000, 0.8000, 0.7143]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m6\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(A\u001b[38;5;241m/\u001b[39mA\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m----> 4\u001b[0m \u001b[43mA\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "## 6 报错，无法broadcast\n",
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
    "print(A/A.sum(axis=0))\n",
    "A/A.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cab41244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "## 7 总是第一个\n",
    "X = torch.randn(3,5,4)\n",
    "print(X.sum(axis=0).shape) # 按照0轴压扁所以 剩下5，4\n",
    "print(X.sum(axis=1).shape) # 按照1轴压扁所以 剩下3，4\n",
    "print(X.sum(axis=2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d5f74c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(19.6066)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 8\n",
    "torch.linalg.norm(torch.randn(3,5,4))\n",
    "torch.linalg.norm(torch.randn(3,5,4,6,7))\n",
    "torch.linalg.norm(torch.randn(3,5,4,6))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "overlay": "<div class='my-top-right'><img height=80px src='http://d2l.ai/_static/logo-with-text.png'/></div><div class='my-top-left'></div>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
