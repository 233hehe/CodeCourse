{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6b57962",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Data Manipulation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31621f5",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "To start, we import the PyTorch library.\n",
    "Note that the package name is `torch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c927bc63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:36:55.160199Z",
     "iopub.status.busy": "2023-02-10T04:36:55.159802Z",
     "iopub.status.idle": "2023-02-10T04:36:56.597445Z",
     "shell.execute_reply": "2023-02-10T04:36:56.593271Z"
    },
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041e94ff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A tensor represents a (possibly multi-dimensional) array of numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a8bf79f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:36:56.605706Z",
     "iopub.status.busy": "2023-02-10T04:36:56.602097Z",
     "iopub.status.idle": "2023-02-10T04:36:56.623829Z",
     "shell.execute_reply": "2023-02-10T04:36:56.622890Z"
    },
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])\n"
     ]
    }
   ],
   "source": [
    "## 创建torch tensor的方法\n",
    "x = torch.arange(12, dtype=torch.float32)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2caf6161",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:36:56.632681Z",
     "iopub.status.busy": "2023-02-10T04:36:56.629172Z",
     "iopub.status.idle": "2023-02-10T04:36:56.648392Z",
     "shell.execute_reply": "2023-02-10T04:36:56.645508Z"
    },
    "origin_pos": 21,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## tensor的元素的个数\n",
    "x.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9cc819",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We can access a tensor's *shape*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e0748ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:36:56.662149Z",
     "iopub.status.busy": "2023-02-10T04:36:56.653612Z",
     "iopub.status.idle": "2023-02-10T04:36:56.672850Z",
     "shell.execute_reply": "2023-02-10T04:36:56.671314Z"
    },
    "origin_pos": 24,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 向量为单纯的X，Y，如果是2darray就是(X,Y)这样\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f07ed96",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Change the shape of a tensor\n",
    "without altering its size or values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31af0393",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:36:56.677744Z",
     "iopub.status.busy": "2023-02-10T04:36:56.676978Z",
     "iopub.status.idle": "2023-02-10T04:36:56.685333Z",
     "shell.execute_reply": "2023-02-10T04:36:56.684233Z"
    },
    "origin_pos": 26,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n",
      "torch.Size([3, 4]) 12\n"
     ]
    }
   ],
   "source": [
    "X = x.reshape(3, 4)\n",
    "print(X)\n",
    "## 你看2d的时候，元素个数不变，但是形态改变\n",
    "print(X.shape, X.numel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca3cde3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can construct a tensor with all elements set to zero\n",
    "or one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f14c0536",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:36:56.694728Z",
     "iopub.status.busy": "2023-02-10T04:36:56.689497Z",
     "iopub.status.idle": "2023-02-10T04:36:56.705823Z",
     "shell.execute_reply": "2023-02-10T04:36:56.704926Z"
    },
    "origin_pos": 30,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c3fbfbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:36:56.718957Z",
     "iopub.status.busy": "2023-02-10T04:36:56.713587Z",
     "iopub.status.idle": "2023-02-10T04:36:56.737180Z",
     "shell.execute_reply": "2023-02-10T04:36:56.734102Z"
    },
    "origin_pos": 35,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((2, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c774b2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sample each element randomly (and independently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48f2ec16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:36:56.745329Z",
     "iopub.status.busy": "2023-02-10T04:36:56.742963Z",
     "iopub.status.idle": "2023-02-10T04:36:56.755089Z",
     "shell.execute_reply": "2023-02-10T04:36:56.754150Z"
    },
    "origin_pos": 40,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2798, -0.6380, -1.1198, -1.1273],\n",
       "        [ 1.1500,  0.7675, -0.4201,  1.6678],\n",
       "        [-2.5294, -0.0221, -1.7760,  2.1427]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27149bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Supplying the exact values for each element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bacefcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:36:56.760675Z",
     "iopub.status.busy": "2023-02-10T04:36:56.759965Z",
     "iopub.status.idle": "2023-02-10T04:36:56.773011Z",
     "shell.execute_reply": "2023-02-10T04:36:56.771920Z"
    },
    "origin_pos": 45,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 4, 3],\n",
       "        [1, 2, 3, 4],\n",
       "        [4, 3, 2, 1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84468efb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`[-1]` selects the last row and `[1:3]`\n",
    "selects the second and third rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7365925a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:36:56.780081Z",
     "iopub.status.busy": "2023-02-10T04:36:56.776551Z",
     "iopub.status.idle": "2023-02-10T04:36:56.792182Z",
     "shell.execute_reply": "2023-02-10T04:36:56.789270Z"
    },
    "origin_pos": 49,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 8.,  9., 10., 11.]),\n",
       " tensor([[ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 选出来是一个tuple，分别是两个torch tensor\n",
    "X[-1], X[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761cbc30",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We can also write elements of a matrix by specifying indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e84d54a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:36:56.801699Z",
     "iopub.status.busy": "2023-02-10T04:36:56.801163Z",
     "iopub.status.idle": "2023-02-10T04:36:56.811524Z",
     "shell.execute_reply": "2023-02-10T04:36:56.808744Z"
    },
    "origin_pos": 52,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5., 17.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1, 2] = 17\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b4194d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To assign multiple elements the same value,\n",
    "we apply the indexing on the left-hand side \n",
    "of the assignment operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2a0cea8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:36:56.817067Z",
     "iopub.status.busy": "2023-02-10T04:36:56.816548Z",
     "iopub.status.idle": "2023-02-10T04:36:56.826215Z",
     "shell.execute_reply": "2023-02-10T04:36:56.823445Z"
    },
    "origin_pos": 56,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12., 12., 12., 12.],\n",
       "        [12., 12., 12., 12.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2, :] = 12\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44470d25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:36:56.830009Z",
     "iopub.status.busy": "2023-02-10T04:36:56.829699Z",
     "iopub.status.idle": "2023-02-10T04:36:56.847664Z",
     "shell.execute_reply": "2023-02-10T04:36:56.846410Z"
    },
    "origin_pos": 61,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([162754.7969, 162754.7969, 162754.7969, 162754.7969, 162754.7969,\n",
       "        162754.7969, 162754.7969, 162754.7969,   2980.9580,   8103.0840,\n",
       "         22026.4648,  59874.1406])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ead6911c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:36:56.861167Z",
     "iopub.status.busy": "2023-02-10T04:36:56.860304Z",
     "iopub.status.idle": "2023-02-10T04:36:56.873803Z",
     "shell.execute_reply": "2023-02-10T04:36:56.872866Z"
    },
    "origin_pos": 66,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3.,  4.,  6., 10.]),\n",
       " tensor([-1.,  0.,  2.,  6.]),\n",
       " tensor([ 2.,  4.,  8., 16.]),\n",
       " tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n",
       " tensor([ 1.,  4., 16., 64.]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## tensor的计算也是element-wise\n",
    "x = torch.tensor([1.0, 2, 4, 8])\n",
    "y = torch.tensor([2, 2, 2, 2])\n",
    "x + y, x - y, x * y, x / y, x ** y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2083c544",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*concatenate* multiple tensors together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2955a7e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:36:56.879245Z",
     "iopub.status.busy": "2023-02-10T04:36:56.878942Z",
     "iopub.status.idle": "2023-02-10T04:36:56.897531Z",
     "shell.execute_reply": "2023-02-10T04:36:56.896610Z"
    },
    "origin_pos": 71,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 2.,  1.,  4.,  3.],\n",
       "         [ 1.,  2.,  3.,  4.],\n",
       "         [ 4.,  3.,  2.,  1.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
       "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "## torch.cat 把两个tensor合在一起\n",
    "torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb8b566",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Construct a binary tensor via *logical statements*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c24b4e60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:36:56.902273Z",
     "iopub.status.busy": "2023-02-10T04:36:56.901655Z",
     "iopub.status.idle": "2023-02-10T04:36:56.914533Z",
     "shell.execute_reply": "2023-02-10T04:36:56.907826Z"
    },
    "origin_pos": 75,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False,  True],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X == Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e3f54e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Summing all the elements in the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "024a541f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:36:56.920128Z",
     "iopub.status.busy": "2023-02-10T04:36:56.919517Z",
     "iopub.status.idle": "2023-02-10T04:36:56.927390Z",
     "shell.execute_reply": "2023-02-10T04:36:56.926574Z"
    },
    "origin_pos": 77,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(66.)\n",
      "tensor([12., 15., 18., 21.]) tensor([ 6., 22., 38.])\n"
     ]
    }
   ],
   "source": [
    "print(X.sum())\n",
    "print(X.sum(dim=0), X.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb238bbf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Perform elementwise binary operations\n",
    "by invoking the *broadcasting mechanism*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b698db05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:36:56.932326Z",
     "iopub.status.busy": "2023-02-10T04:36:56.931122Z",
     "iopub.status.idle": "2023-02-10T04:36:56.940140Z",
     "shell.execute_reply": "2023-02-10T04:36:56.939336Z"
    },
    "origin_pos": 81,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [2]]) tensor([[0, 1]])\n",
      "tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]])\n"
     ]
    }
   ],
   "source": [
    "## 即使形状不同，仍然存在广播机制，a和b都是2d tensor，a+b的广播机制是a的每一行都会加入b的每一行，b的每一列和a的每一列增加。变成了矩阵相加\n",
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "print(a, b)\n",
    "print(a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d7c997",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Running operations can cause new memory to be\n",
    "allocated to host results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4189ca33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:36:56.963682Z",
     "iopub.status.busy": "2023-02-10T04:36:56.963221Z",
     "iopub.status.idle": "2023-02-10T04:36:56.978567Z",
     "shell.execute_reply": "2023-02-10T04:36:56.976043Z"
    },
    "origin_pos": 87,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(Y)\n",
    "Y = Y + X\n",
    "id(Y) == before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d522963",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Performing in-place operations  \n",
    "如果原地操作，要么新建一个container，更新这个container，要么就替换原本的X或者Y的value。\n",
    "这就跟numpy array 的np.concat会临时增加多倍的内存，如果新建一个numpy的container，然后更新每个部分，这样可以省下大量的memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7777452b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:36:56.986726Z",
     "iopub.status.busy": "2023-02-10T04:36:56.986273Z",
     "iopub.status.idle": "2023-02-10T04:36:57.002406Z",
     "shell.execute_reply": "2023-02-10T04:36:56.997682Z"
    },
    "origin_pos": 92,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id(Z): 2334355999616\n",
      "id(Z): 2334355999616\n"
     ]
    }
   ],
   "source": [
    "Z = torch.zeros_like(Y)\n",
    "print('id(Z):', id(Z))\n",
    "Z[:] = X + Y\n",
    "print('id(Z):', id(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423b87fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If the value of `X` is not reused in subsequent computations,\n",
    "we can also use `X[:] = X + Y` or `X += Y`\n",
    "to reduce the memory overhead of the operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30a68e8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:36:57.006251Z",
     "iopub.status.busy": "2023-02-10T04:36:57.005866Z",
     "iopub.status.idle": "2023-02-10T04:36:57.016728Z",
     "shell.execute_reply": "2023-02-10T04:36:57.015796Z"
    },
    "origin_pos": 97,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(X)\n",
    "X += Y\n",
    "id(X) == before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705d24b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Converting to a NumPy tensor (`ndarray`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5b8d0da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:36:57.021703Z",
     "iopub.status.busy": "2023-02-10T04:36:57.020430Z",
     "iopub.status.idle": "2023-02-10T04:36:57.031319Z",
     "shell.execute_reply": "2023-02-10T04:36:57.028267Z"
    },
    "origin_pos": 103,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, torch.Tensor)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = X.numpy()\n",
    "B = torch.from_numpy(A)\n",
    "type(A), type(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dee15b",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Convert a size-1 tensor to a Python scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d92b220a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T04:36:57.043397Z",
     "iopub.status.busy": "2023-02-10T04:36:57.038275Z",
     "iopub.status.idle": "2023-02-10T04:36:57.054596Z",
     "shell.execute_reply": "2023-02-10T04:36:57.053558Z"
    },
    "origin_pos": 108,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.5000]), 3.5, 3.5, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([3.5])\n",
    "a, a.item(), float(a), int(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e19f63f",
   "metadata": {},
   "source": [
    "## 练习部分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795a68ec",
   "metadata": {},
   "source": [
    "运行本节中的代码。将本节中的条件语句X == Y更改为X < Y或X > Y，然后看看你可以得到什么样的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "199306fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True],\n",
       "        [ True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X>Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799113de",
   "metadata": {},
   "source": [
    "用其他形状（例如三维张量）替换广播机制中按元素操作的两个张量。结果是否与预期相同？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b89792f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5]]) tensor([[0, 1, 2, 3]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (4) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(a, b)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (4) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "## 但是如果shape的size不相同，就不可以广播\n",
    "a = torch.arange(6).reshape((3, 2))\n",
    "b = torch.arange(4).reshape((1, 4))\n",
    "print(a, b)\n",
    "print(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07d58e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [2]]) tensor([[0, 1, 2]])\n",
      "tensor([[0, 1, 2],\n",
      "        [1, 2, 3],\n",
      "        [2, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(3).reshape((1, 3))\n",
    "print(a, b)\n",
    "print(a + b)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "overlay": "<div class='my-top-right'><img height=80px src='http://d2l.ai/_static/logo-with-text.png'/></div><div class='my-top-left'></div>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
